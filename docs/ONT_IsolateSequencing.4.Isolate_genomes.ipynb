{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ONT sequencing data processing for prokaryote isolates\n",
    "\n",
    "# Isolate genomes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate genome stats, taxonomy predictions, and gene annotation predictions for assembled isolate genomes.\n",
    "\n",
    "This is directly analogous to the steps outlined in the metagenomics processing pipeline (e.g. [here](https://github.com/GenomicsAotearoa/environmental_metagenomics)). In this case, we are inputting isolate genomes assembled from Nanopore long read sequencing data compared with metagenome-assembled genomes generated from Illumina HiSeq sequencing, but the process is the same.\n",
    "\n",
    "**Important caveat**: Several of these tools will not work well if assembled contigs from more than one organism are present (e.g. if your starting cultures are not pure cultures). If you know your samples are contain more than one organism in advance (and/or results from CheckM and gtdb suggest there may be more than one organism present), it will first be necessary to separate out genomes of individual organisms. In simple cases (e.g. your target organism + 1 contaminating organism) with genomes assembled into relatively complete single contigs, this might be possible by manually splitting the contigs into separate fna files. For more complex situations, you will need to do this via binning into separate genomes. This is not covered here, but should be analogous to the process described in the [metagenomics processing pipeline](https://github.com/GenomicsAotearoa/environmental_metagenomics) (although the tools *may* need to be specific for long read data)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Genome stats via CheckM\n",
    "\n",
    "See the metagenomics processing pipeline [here](https://github.com/GenomicsAotearoa/environmental_metagenomics) for more detailed information.\n",
    "\n",
    "Note: CheckM v1 and v2 are built differently and can produce different results. E.g. CheckM2 reportedly handles ultrasmall prokaryote genomes better, but may introduce some errors in placing some bacterial lineages. It can be worth trying both."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Genome stats via *checkM1*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "#SBATCH -A <>\n",
    "#SBATCH -J checkm\n",
    "#SBATCH --time 08:00:00\n",
    "#SBATCH --ntasks=1\n",
    "#SBATCH --mem 60GB\n",
    "#SBATCH --cpus-per-task=20\n",
    "#SBATCH -e checkm.err\n",
    "#SBATCH -o checkm.out\n",
    "\n",
    "cd /work/dir\n",
    "mkdir -p 3.isolate_genomes/1.checkm1\n",
    "\n",
    "module purge\n",
    "module load CheckM/1.2.3-foss-2023a-Python-3.11.6\n",
    "\n",
    "checkm lineage_wf -t 20 --pplacer_threads 10 --tab_table \\\n",
    "-x fna \\\n",
    "-f 3.isolate_genomes/1.checkm1/checkm_bin_summary.txt \\\n",
    "2.assembly/2.assembly.LR_polished.fna_files.m1000/ \\\n",
    "3.isolate_genomes/1.checkm1/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Genome stats via *CheckM2*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "#SBATCH -A <>\n",
    "#SBATCH -J checkm2\n",
    "#SBATCH --time 12:00:00\n",
    "#SBATCH --ntasks=1\n",
    "#SBATCH --mem 120GB\n",
    "#SBATCH --cpus-per-task=20\n",
    "#SBATCH -e checkm2.err\n",
    "#SBATCH -o checkm2.out\n",
    "\n",
    "cd /work/dir\n",
    "mkdir -p 3.isolate_genomes/1.checkm2\n",
    "\n",
    "module purge\n",
    "module load CheckM2/1.0.1-Miniconda3\n",
    "\n",
    "checkm2 predict --force --threads ${SLURM_CPUS_PER_TASK} -x fna \\\n",
    "--input 2.assembly/2.assembly.LR_polished.fna_files.m1000 \\\n",
    "--output-directory 3.isolate_genomes/1.checkm2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Taxonomy prediction via *gtdb*\n",
    "\n",
    "Generate taxonomy predictions for each isolate via *gtdb-tk*. (See the metagenomics processing pipeline [here](https://github.com/GenomicsAotearoa/environmental_metagenomics) for more detailed information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "#SBATCH -A <>\n",
    "#SBATCH -J gtdbtk\n",
    "#SBATCH --time 04:00:00\n",
    "#SBATCH --ntasks=1\n",
    "#SBATCH --mem 100GB\n",
    "#SBATCH --cpus-per-task=20\n",
    "#SBATCH -e gtdbtk.err\n",
    "#SBATCH -o gtdbtk.out\n",
    "\n",
    "cd /work/dir\n",
    "mkdir -p 3.isolate_genomes/2.gtdbtk\n",
    "\n",
    "module purge\n",
    "module load GTDB-Tk/2.4.0-foss-2023a-Python-3.11.6\n",
    "\n",
    "gtdbtk classify_wf --cpus ${SLURM_CPUS_PER_TASK} \\\n",
    "-x fna --skip_ani_screen \\\n",
    "--genome_dir 2.assembly/2.assembly.LR_polished.fna_files.m1000 \\\n",
    "--out_dir 3.isolate_genomes/2.gtdbtk\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary table of genome stats and taxonomy\n",
    "\n",
    "Example python script to generate summary table of *checkM* results and *gtdb* taxonomy predictions. \n",
    "\n",
    "In this example, we will also incorporate the previously generated summary table of polished assembly stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working directory\n",
    "cd /working/dir\n",
    "\n",
    "# Load python\n",
    "module purge\n",
    "module load Python/3.8.2-gimkl-2020a\n",
    "python3\n",
    "\n",
    "## Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import glob\n",
    "\n",
    "## Compile results\n",
    "\n",
    "# polished assembly stats\n",
    "assembly_stats_df = pd.read_csv('2.assembly/2.assembly.LR_polished.assembly_stats/summary_table.polished_assembly.stats.tsv', sep='\\t')\n",
    "# checkm\n",
    "checkm_df = pd.read_csv('3.isolate_genomes/1.checkm1/checkm_bin_summary.txt', sep='\\t')[['Bin Id', 'Completeness', 'Contamination', 'Strain heterogeneity']].rename({'Bin Id': 'sampleID'}, axis=1)\n",
    "# taxonomy\n",
    "gtdb_df = pd.concat([pd.read_csv(f, sep='\\t') for f in glob.glob(\"3.isolate_genomes/2.gtdbtk/*.summary.tsv\")],\n",
    "                      ignore_index=True)[['user_genome', 'classification']]\n",
    "gtdb_df.columns = ['isolateID', 'taxonomy_gtdb']\n",
    "\n",
    "# # If necessary, strip '.consensus' off sampleIDs for merging\n",
    "# checkm_df['isolateID'] = checkm_df['isolateID'].str.replace(r'.consensus', '')\n",
    "# gtdb_df['isolateID'] = gtdb_df['isolateID'].str.replace(r'.consensus', '')\n",
    "\n",
    "# Compile into one table\n",
    "summary_df = pd.merge(assembly_stats_df, checkm_df, how=\"outer\", on=\"sampleID\").merge(gtdb_df, how=\"outer\", on=\"sampleID\")\n",
    "\n",
    "# Write out summary table\n",
    "summary_df.to_csv('3.isolate_genomes/summary_table_checkm_gtdb.tsv', sep='\\t', index=False)\n",
    "\n",
    "quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gene Calling and Annotation\n",
    "\n",
    "#### Introduction\n",
    "\n",
    "As per the metagenomics processing pipeline, we can now predict genes and the annotations of those genes for each of our assembled isolate genomes.\n",
    "\n",
    "*prodigal* is a commonly used tool for calling genes. This can also be combined with other tools to call, for example, rRNA (*metaxa2*) and tRNA (*aragorn*). Identified genes can then be searched against a suite of gene annotation databases, such as *KEGG*, *UniProt*, *UniRef*, *pfam*, *tigrfam*, etc. to generate predicted annotations for each gene (e.g. searches via *blast*, *usearch*, *diamond*, or *hmmsearch*). Finally, these can be compiled to generate a single user friendly table of all annotation predictions (by each of the databases searched against) for each called gene.\n",
    "\n",
    "*DRAM* is a convenient annotation tool that completes each of the above steps for a set of common annotation databases and compiles a user friendly output table of predicted gene annotations. In the example below, we will run gene calling and annotation via *DRAM*, which is installed as a NeSI module.\n",
    "\n",
    "For more information on *DRAM*, see here: https://github.com/WrightonLabCSU/DRAM\n",
    "\n",
    "NOTE:\n",
    "\n",
    "- *DRAM* comes installed with a number of freely available databases that it searches against. The full *KEGG* database, however, requires a paid licence, and is not available as part of the NeSI module. Unfortunately the *DRAM* version 1.3 (e.g. NeSI module `DRAM/1.3.5-Miniconda3`) cannot be set to include the full *KEGG* database, even if you have a full *KEGG* licence in your group (as the config file pointing to database locations is a fixed setting in DRAM < v1.4). However, future versions of *DRAM* (from v1.4) are reportedly going to include an extra option to set your own config file (including options to copy the current config file to retrieve the NeSI paths to the rest of the available databases, which can then be modified to include your own database (e.g. the full *KEGG* database)). (*DRAM_1.4* includes several major updates, so will hopefully be upgraded in NeSI in the future).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gene prediction and annotation via *DRAM*\n",
    "\n",
    "Note: We may no longer have the full sequential set of 96 sampleIDs (due to some samples failing to assemble). To save wasting resources running jobs on missing samples, we previously suggested you could list the exact sampleID numbers in the `#SBATCH --array=` line. As an alternative, here we will:\n",
    "\n",
    "- Inside the slurm script:\n",
    "  - generate an array of all assembly file names (`ASSEMBLY_FILES_ARRAY`)\n",
    "  - extract an individual file name from this array based on the `SLURM_ARRAY_TASK_ID`\n",
    "  - use this individual file name for input and output names\n",
    "- submitting slurm job:\n",
    "  - add `--array=0-n` to the slurm submission based on the assembly file count.\n",
    "  \n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "isolate_genomes_DRAM.sl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "#SBATCH -A your_project_account\n",
    "#SBATCH -J isolate_genomes_DRAM\n",
    "#SBATCH --time 2-00:00:00\n",
    "#SBATCH --mem 100GB\n",
    "#SBATCH --ntasks=1\n",
    "#SBATCH --cpus-per-task=36\n",
    "#SBATCH -e isolate_genomes_DRAM_%a.err\n",
    "#SBATCH -o isolate_genomes_DRAM_%a.out\n",
    "\n",
    "# Working directory\n",
    "cd /working/dir\n",
    "mkdir -p 3.isolate_genomes/3.gene_annotations/dram_annotation/isolate_subsets\n",
    "\n",
    "# Load module \n",
    "module purge\n",
    "module load DRAM/1.3.5-Miniconda3\n",
    "\n",
    "# array of assembly files\n",
    "ASSEMBLY_FILES_ARRAY=(2.assembly/2.assembly.LR_polished.fna_files.m1000/*.fna)                    \n",
    "# Set variables\n",
    "ASSEMBLY_FILE=$(echo ${ASSEMBLY_FILES_ARRAY[${SLURM_ARRAY_TASK_ID}]})\n",
    "OUTPUT_FILE=$(basename ${ASSEMBLY_FILE} .fna)\n",
    "\n",
    "## Run DRAM\n",
    "# n.b. can add --gtdb_taxonomy twice *if* there's also an ar122 summary file available\n",
    "DRAM.py annotate --threads 36 --use_uniref \\\n",
    "--input_fasta ${ASSEMBLY_FILE} \\\n",
    "--checkm_quality 3.isolate_genomes/1.checkm1/checkm_bin_summary.txt \\\n",
    "--gtdb_taxonomy 3.isolate_genomes/2.gtdbtk/gtdbtk.bac120.summary.tsv \\\n",
    "-o 3.isolate_genomes/3.gene_annotations/dram_annotation/isolate_subsets/${OUTPUT_FILE}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "ASSEMBLY_FILES_ARRAY=( $(ls 2.assembly/2.assembly.LR_polished.fna_files.m1000/*.fna) )\n",
    "ZNUM=$(( ${#ASSEMBLY_FILES_ARRAY[@]} - 1 ))\n",
    "sbatch --array=0-${ZNUM} isolate_genomes_DRAM.sl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge *DRAM* annotations via *compile_dram_annotations.py*\n",
    "\n",
    "The script `compile_dram_annotations.py` was written to recompile subsets of DRAM outputs, while allowing for cases where some results files were not generated (e.g. no tRNAs were identified for a given subset). It takes as input the directory path that contains each of the *DRAM* subsets outputs. This script is available in `../scripts/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working directory\n",
    "cd /working/dir/3.isolate_genomes/3.gene_annotations\n",
    "\n",
    "# Load python\n",
    "module purge\n",
    "module load Python/3.8.2-gimkl-2020a\n",
    "\n",
    "# Run compile dram annotations\n",
    "/path/to/scripts/compile_dram_annotations.py \\\n",
    "-i dram_annotation/isolate_subsets/ \\\n",
    "-o dram_annotation/collated_dram_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *DRAM* distill\n",
    "\n",
    "`DRAM.py distill` can be used to generate summaries of annotations and some metabolic pathways.\n",
    "\n",
    "For more information, see here: https://github.com/WrightonLabCSU/DRAM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working directory\n",
    "cd /working/dir/3.isolate_genomes/3.gene_annotations\n",
    "\n",
    "# Load modules\n",
    "module purge\n",
    "module load DRAM/1.3.5-Miniconda3\n",
    "\n",
    "# Run DRAM\n",
    "DRAM.py distill \\\n",
    "-i dram_annotation/collated_dramv_annotations.tsv \\\n",
    "-o dram_distillation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
