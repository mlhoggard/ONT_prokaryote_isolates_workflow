{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ONT sequencing data processing for prokaryote isolates\n",
    "\n",
    "# Assembly\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Assembly\n",
    "\n",
    "There a several options for assemblers for long read data. In this example, we will use *Flye*\n",
    "\n",
    "Useful outputs:\n",
    "\n",
    "- `assembly.fasta`: draft assembly\n",
    "- `tail flye.log`: basic assembly stats\n",
    "- `assembly_info.txt`: more info on each contig in the assembly\n",
    "\n",
    "NOTE:\n",
    "\n",
    "- *Flye* has an option to account for uneven coverage (e.g. metagenomics data or data generated from non-pure isolates): `--meta`. This can optionally be included in case there are more than one organism in what might be presumed to be a pure isolate (or if the originating sample was already known to be mixed (i.e. more than one genome in the sample))\n",
    "- *Flye* has three *nano* options\n",
    "  - `nano_corr`: Assumes data are pre-cleaned via, e.g., illumina reads, prior to assembly\n",
    "  - `nano_raw`: Assumes older poor quality reads, but can also use on HAC data\n",
    "  - `nano_hq`: Good for SUP-called reads, but can also be used for HAC reads\n",
    "    - When working with HAC data, this option *might* return more split contigs. However, preliminary testing in our group did not suggested an appreciable difference between `nano_raw` and `nano_hq` with HAC data. You may wish to try both with your data and assess the assemblies generated.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run *Flye* assemblies\n",
    "\n",
    "Run *Flye* assemblies for each barcode. These can be relatively quick, so could be run in a loop, but this can also be sped up by running via slurm array (`#SBATCH --array=1-96`) as in the example below.\n",
    "\n",
    "NOTE:\n",
    "\n",
    "- Running *Flye* with `--meta` flag and `--nano-hq` setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "#SBATCH -A <your_project_account>\n",
    "#SBATCH -J 2_assembly\n",
    "#SBATCH --time 00:45:00\n",
    "#SBATCH --array=1-96\n",
    "#SBATCH --ntasks=1\n",
    "#SBATCH --mem 10GB\n",
    "#SBATCH --cpus-per-task=16\n",
    "#SBATCH -e 2_assembly_%a.err\n",
    "#SBATCH -o 2_assembly_%a.out\n",
    "\n",
    "cd /working/dir\n",
    "mkdir -p 2.assembly/1.assembly.flye\n",
    "\n",
    "module purge\n",
    "module load Flye/2.9-gimkl-2020a-Python-3.8.2\n",
    "\n",
    "srun flye --meta -t ${SLURM_CPUS_PER_TASK} \\\n",
    "--nano-hq 1.trimmed_and_filtered_reads/1.chopper/fastq_files/S${SLURM_ARRAY_TASK_ID}.chopper.fastq \\\n",
    "--o 2.assembly/1.assembly.flye/S${SLURM_ARRAY_TASK_ID}.assembly\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Some assemblies may fail (e.g. where no contigs are assembled). This may be due to, for example; poor coverage for this isolate; insufficient data (similar to poor coverage); mixed genomes in a single sample that the assembler is struggling to resolve. Take a note of failed isolateIDs, as this will be useful to know to exclude these isolates downstream.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate summary table of assembly_info.txt outputs\n",
    "\n",
    "Merge *Flye* `assembly_info.txt` outputs into one summary table \n",
    "\n",
    "Example python code for compiling all assembly_info.txt files into a summary table. \n",
    "\n",
    "Note:\n",
    "\n",
    "- The code below includes a try-execpt clause to allow for cases where assembly failed for some isolates.\n",
    "- Modify `range(1,96)` to match your sampleIDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd /working/dir\n",
    "\n",
    "module purge\n",
    "module load Python/3.8.2-gimkl-2020a\n",
    "python3\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Compile flye assembly_info results\n",
    "results_list = []\n",
    "for i in range(1,96):\n",
    "    try:\n",
    "        tmp_df = pd.read_csv('2.assembly/1.assembly.flye/S'+str(i)+'.assembly/assembly_info.txt', sep='\\t').rename({'#seq_name': 'contigID'}, axis=1)    \n",
    "    except FileNotFoundError:\n",
    "        continue\n",
    "    tmp_df.index = ['S'+str(i)]*len(tmp_df)\n",
    "    tmp_df = tmp_df.rename_axis('sampleID').reset_index()\n",
    "    results_list.append(tmp_df)\n",
    "\n",
    "# Generate summary table and write out\n",
    "results_df = pd.concat(results_list, axis=0)\n",
    "# counts of contigs per sample\n",
    "counts_df = results_df.groupby('sampleID').size().reset_index(name='perSample_contig_counts')\n",
    "results_df = pd.merge(results_df, counts_df, on = 'sampleID')\n",
    "results_df.to_csv('2.assembly/1.assembly.flye/assembly_info.sumary_table.tsv', sep='\\t', index=False)\n",
    "\n",
    "quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Long-read polishing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Long-read polishing takes the assemblies that were generated above and maps reads to them and checks and revises them. There are several options for this step, such as *racon* and *medaka*. In the example below, we will use *medaka*.\n",
    "\n",
    "*medaka* is Oxford Nanopore's in-house assembly polisher. It takes sequences, assembly files, and the model used for basecalling, and generates polished assembly files.\n",
    "\n",
    "NOTE:\n",
    "\n",
    "- to find model options, run: `medaka tools list_models`, and then select the applicable model for your basecalling on this specific run.\n",
    "- For this example data, models and software versions used for basecalling:\n",
    "  - Basecalling software: `Dorado/0.7.3`\n",
    "  - Basecalling model: `dna_r10.4.1_e8.2_400bps_sup@v5.0.0` \n",
    "  - Kit: `--kit-name SQK-RBK114-96`\n",
    "  - for latest medaka in NeSI at the time (1.11.1), the latest model available = `r1041_e82_400bps_sup_v4.2.0`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run *medaka* long read polishing of *Flye* assembly\n",
    "\n",
    "Run *medaka* polishing and then copy all polished assembly files into one output directory\n",
    "\n",
    "NOTE:\n",
    "\n",
    "- In this example, the basecalling model was `dna_r10.4.1_e8.2_400bps_sup@v5.0.0`. However, the latest model available in *medaka* at the time was `r1041_e82_400bps_sup_v4.2.0`. Update `-m r1041_e82_400bps_sup_v4.2.0` if the basecalling model was different for your run.\n",
    "- If some samples failed the assembly step, you could exclude these from the slurm array in this script, as they will only result in failed surm jobs here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "#SBATCH -A <>\n",
    "#SBATCH -J 1_assembly_polish\n",
    "#SBATCH --time 06:00:00\n",
    "#SBATCH --ntasks=1\n",
    "#SBATCH --mem 30GB\n",
    "#SBATCH --array=1-96\n",
    "#SBATCH --cpus-per-task=8\n",
    "#SBATCH -e 1_assembly_polish_%a.err\n",
    "#SBATCH -o 1_assembly_polish_%a.out\n",
    "\n",
    "# Working directory\n",
    "cd /work/dir\n",
    "mkdir -p 2.assembly/2.assembly.LR_polished\n",
    "\n",
    "# load module\n",
    "module purge\n",
    "module load medaka/1.11.1-Miniconda3-22.11.1-1\n",
    "\n",
    "# Run medaka\n",
    "medaka_consensus -f -t ${SLURM_CPUS_PER_TASK} \\\n",
    "-m r1041_e82_400bps_sup_v4.2.0 \\\n",
    "-i 0.raw_data/2.basecalled.demux/S${SLURM_ARRAY_TASK_ID}.fastq \\\n",
    "-d 2.assembly/1.assembly.flye/S${SLURM_ARRAY_TASK_ID}.assembly/assembly.fasta \\\n",
    "-o 2.assembly/2.assembly.LR_polished/S${SLURM_ARRAY_TASK_ID}.assembly.polished\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Copy polished assembly files into one directory and rename fna files with sampleID\n",
    "\n",
    "- n.b. can ignore `No such file or directory` error messages (assuming they match the samples that failed to assemble any contigs in the assembly step above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd /work/dir\n",
    "mkdir -p 2.assembly/2.assembly.LR_polished.fna_files\n",
    "\n",
    "for i in {1..96}; do\n",
    "    cp 2.assembly/2.assembly.LR_polished/S${i}.assembly.polished/consensus.fasta \\\n",
    "    2.assembly/2.assembly.LR_polished.fna_files/S${i}.assembly.polished.fna\n",
    "done\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating polished assemblies\n",
    "\n",
    "It always pays to assess the quality of final assemblies. There as numerous tools to do this and metrics you can assess. Here we will get basic stats via contig counts, contig lengths, and NL50 stats via `stats.sh` from the *BBMap* suite of tools. We can then use a bash script to generate summary table from BBMap's stats.sh output.\n",
    "\n",
    "NOTE: \n",
    "\n",
    "- The script below runs in a loop over all 96 sampleIDs, but some samples may not have files available here if they failed to assemble any contigs in the assembly step. We can ignore the following error message: `Exception in thread \"main\" java.lang.RuntimeException: Input file does not appear to be valid` (assuming they match the samples that failed to assemble any contigs in the assembly step above)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working directory\n",
    "cd /work/dir\n",
    "mkdir -p 2.assembly/2.assembly.LR_polished.assembly_stats\n",
    "\n",
    "# load module\n",
    "module purge\n",
    "module load BBMap/38.95-gimkl-2020a\n",
    "\n",
    "for i in {1..96}; do\n",
    "    stats.sh in=2.assembly/2.assembly.LR_polished.fna_files/S${i}.assembly.polished.fna > 2.assembly/2.assembly.LR_polished.assembly_stats/S${i}.assembly.polished.stats\n",
    "done\n",
    "\n",
    "# Extract key stats from outputs and compile into single summary table\n",
    "echo -e \"sampleID\\tcontig_count\\tcontig_length_max\\tcontig_length_total\\tcontig_NL50\" \\\n",
    "> 2.assembly/2.assembly.LR_polished.assembly_stats/summary_table.polished_assembly.stats.tsv\n",
    "for i in {1..96}; do\n",
    "    infile=\"2.assembly/2.assembly.LR_polished.assembly_stats/S${i}.assembly.polished.stats\"\n",
    "    SampleID=\"S${i}\"\n",
    "    contig_count=$(sed -n -e 's/Main genome contig total:[[:space:]]\\+//p' ${infile})\n",
    "    contig_length_max=$(sed -n -e 's/Max contig length:[[:space:]]\\+//p' ${infile})\n",
    "    contig_length_total=$(sed -n -e 's/Main genome contig sequence total:[[:space:]]\\+\\(.*MB\\).*/\\1/p' ${infile})\n",
    "    contig_NL50=$(sed -n -e 's/Main genome contig N\\/L50:[[:space:]]\\+//p' ${infile})\n",
    "    echo -e \"${SampleID}\\t${contig_count}\\t${contig_length_max}\\t${contig_length_total}\\t${contig_NL50}\" \\\n",
    "    >> 2.assembly/2.assembly.LR_polished.assembly_stats/summary_table.polished_assembly.stats.tsv\n",
    "done\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Short-read polishing\n",
    "\n",
    "Historically, Nanopore long-read sequencing has suffered from high error rates, and methods were developed to polish long-read assemblies via adding high quality short read (such as Illumina HiSeq) data as well. Some assembly algorithms have also been developed that take *both* long read and short read data together when generating assemblies (i.e. hybrid assemblies). \n",
    "\n",
    "Recent advances have considerably increased Nanopore basecalling quality, and ensuring a high sequencing coverage across the genome also likely helps mitigate some of the remaining errors. \n",
    "\n",
    "In one small pilot test within our group, *checkM* completeness and contamination stats were comparable between only long-read polished isolate data and both long- and short-read polished data. Although, the quality and consistency at the individual base level was not tested, and how important this is for your study may depend on what you're asking of the data downstream. \n",
    "\n",
    "We will not cover the process of short-read polishing in these docs, but it is worth considering for your data and study question whether you wish to include this step here. Ultimately, if you have high quality short-read data available, or it is easily obtainable, it is likely to be beneficial to incorporate them here. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assembly post-processing\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add isolateIDs to contig headers\n",
    "\n",
    "It can be useful for downstream applications (particularly where assembled contigs from all sequenced isolates are analysed together) to add isolateIDs into the headers of contigIDs for each isolate assembly.\n",
    "\n",
    "The script below uses *sed* to do this in place on the `2.assembly.LR_polished.fna_files`. (If you wish to keep these original files unedited, you can remove the `-i` flag and instead read the result into a new file via `>`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd /working/dir\n",
    "\n",
    "for i in {1..96}; do\n",
    "    sed -i -e \"s/>/>S${i}_/g\" 2.assembly/2.assembly.LR_polished.fna_files/S${i}.assembly.polished.fna\n",
    "done\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtering out short contigs from assemblies\n",
    "\n",
    "Short contigs often contain little biologically useful information and can create additional noise in downstream analyses. In this example we will filter these out via *seqmagick*.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd /work/dir\n",
    "\n",
    "module purge\n",
    "module load seqmagick/0.8.4-gimkl-2020a-Python-3.8.2\n",
    "\n",
    "mkdir -p 2.assembly/2.assembly.LR_polished.fna_files.m1000\n",
    "\n",
    "for file in 2.assembly/2.assembly.LR_polished.fna_files/*.fna; do\n",
    "    filename=$(basename ${file} .fna)\n",
    "    seqmagick convert --min-length 1000 ${file} 2.assembly/2.assembly.LR_polished.fna_files.m1000/${filename}.m1000.fna\n",
    "done\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate assembly2contig_lookupTable\n",
    "\n",
    "A lookup table mapping all contig IDs to assembly IDs for all assemblies can be useful in some cases for downstream applications.\n",
    "\n",
    "If this is of use, you can use the python code below to generate `assembly2contig_lookupTable.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working directory\n",
    "cd /work/dir\n",
    "\n",
    "# Load python\n",
    "module purge\n",
    "module load Python/3.8.2-gimkl-2020a\n",
    "python3\n",
    "\n",
    "### Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from Bio.SeqIO.FastaIO import SimpleFastaParser\n",
    "import re\n",
    "import os\n",
    "\n",
    "# Compile genome2contig lookup tables\n",
    "with open('2.assembly/2.assembly.LR_polished/assembly2contig_lookupTable.tsv', 'w') as write_file:\n",
    "    # header\n",
    "    write_file.write('assemblyID\\tcontigID\\n')\n",
    "    # Prok bins\n",
    "    assemblyfiles_directory = os.fsencode('2.assembly/2.assembly.LR_polished.fna_files')\n",
    "    for file in os.listdir(assemblyfiles_directory):\n",
    "        filename = os.fsdecode(file)\n",
    "        assemblyID = os.path.splitext(filename)[0]\n",
    "        with open('2.assembly/2.assembly.LR_polished.fna_files/' + filename, 'r') as read_fasta:\n",
    "            for name, seq in SimpleFastaParser(read_fasta):\n",
    "                write_file.write(assemblyID + '\\t' + name + '\\n')\n",
    "\n",
    "# Compile genome2contig lookup tables - m1000 filtered contigs\n",
    "with open('2.assembly/2.assembly.LR_polished/assembly2contig_lookupTable.m1000.tsv', 'w') as write_file:\n",
    "    # header\n",
    "    write_file.write('assemblyID\\tcontigID\\n')\n",
    "    # Prok bins\n",
    "    assemblyfiles_directory = os.fsencode('2.assembly/2.assembly.LR_polished.fna_files.m1000')\n",
    "    for file in os.listdir(assemblyfiles_directory):\n",
    "        filename = os.fsdecode(file)\n",
    "        assemblyID = os.path.splitext(filename)[0]\n",
    "        with open('2.assembly/2.assembly.LR_polished.fna_files.m1000/' + filename, 'r') as read_fasta:\n",
    "            for name, seq in SimpleFastaParser(read_fasta):\n",
    "                write_file.write(assemblyID + '\\t' + name + '\\n')\n",
    "\n",
    "quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
